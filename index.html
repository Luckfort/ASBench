<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents</title>
  <link rel="icon" type="image/x-icon" href="static/images/robot.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents</h1>
                  <div class="is-size-5 publication-authors">
                    <!-- Paper authors -->
                    <span class="author-block">
                      <a href="https://zhang-henry.github.io/">Hanrong Zhang</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://luckfort.github.io/">Jingyuan Huang</a><sup>2</sup>,</span>
                    <span class="author-block">
                        <a href="https://dongyuanjushi.github.io/">Kai Mei</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=XLOJ7R0AAAAJ">Yifei Yao</a><sup>1</sup>,</span>
                    <p></p>
                    <span class="author-block">
                      <a href="https://zhentingwang.github.io/">Zhenting Wang</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=XY2MhmoAAAAJ">Chenlu Zhan</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://dske.zju.edu.cn/people_profile/?user_id=3">Hongwei Wang</a><sup>1</sup>,</span>
                    <span class="author-block">
                      <a href="https://yongfeng.me/">Yongfeng Zhang</a><sup>2</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Zhejiang University,</span>
                    <span class="author-block"><sup>2</sup>Rutgers University</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>-->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.02644"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--<span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/agiresearch/ASB"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--<span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>-->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Opening Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div align=center>
        <img src="./static/images/LLM Agent Attack.jpg" alt="Agent Attack" style="width: 100%;">
        <h2 class="subtitle has-text-centered">
          <div align=justify>
            Overview of the LLM Agent Attacking Framework, including Direct Prompt Injections (DPI), Observation Prompt Injections (OPI), Plan-of-Thought (PoT) Backdoor, and Memory Poisoning Attacks, which target the user query, observations, system prompts, and memory retrieval respectively of the agent during action planning and execution.
          </div>
        </h2>
      </div>
    </div>
  </div>
</section>
<!-- Opening Image -->

<!-- Abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Although LLM-based agents, powered by Large Language Models (LLMs), can use external tools and memory mechanisms to solve complex real-world tasks, they may also introduce critical security vulnerabilities. However, the existing literature does not comprehensively evaluate attacks and defenses against LLM-based agents. </p>
          
          <p>To address this, we introduce <span class="dnerf">Agent Security Bench (ASB)</span>, a comprehensive framework designed to formalize, benchmark, and evaluate the attacks and defenses of LLM-based agents, including 10 scenarios (e.g., e-commerce, autonomous driving, finance), 10 agents targeting the scenarios, over 400 tools, 23 different types of attack/defense methods, and 8 evaluation metrics. </p>
          
          <p>Based on <span class="dnerf">ASB</span>, we benchmark 10 prompt injection attacks, a memory poisoning attack, a novel Plan-of-Thought backdoor attack, a mixed attack, and 10 corresponding defenses across 13 LLM backbones with nearly 90,000 testing cases in total. </p>
          
          <p>Our benchmark results reveal critical vulnerabilities in different stages of agent operation, including system prompt, user prompt handling, tool usage, and memory retrieval, with the highest average attack success rate of 84.30%, but limited effectiveness shown in current defenses, unveiling important works to be done in terms of agent security for the community. Our code can be found at 
          <a href="https://github.com/agiresearch/ASB">
            <span>https://github.com/agiresearch/ASB</span>.
          </a></p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Abstract -->


<!-- Attack Methods on Agents -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div align=center>
        <h2 class="title is-3">⚔️Attack Methods on Agents</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <div class="image-body">
          <div align=center>
            <img src="./static/images/DPI.png" alt="Agent Attack" style="width: 70%;">
          </div>
        </div>
        <h3 class="subtitle has-text-centered">
          <div align=justify>
            In <i>DPI</i> scenario, a third-party attacker appends a malicious command to the user's prompt, instructing the <i>Data Export</i> tool to leak the latest financial reports. When the LLM processes the combined user prompt and the injected attack command, it interferes with the reasoning process of the <i>system_admin_agent</i>, altering its internal logic. The manipulated plan generated by the LLM enables the export and leak of sensitive financial data. As a result, by following the manipulated plan, the agent utilizes the <i>Data Export</i> tool to fulfill the attacker's intent.
          </div>
        </h3>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="image-body">
          <div align=center>
            <img src="./static/images/OPI.png" alt="Agent Attack" style="width: 70%;">
          </div>
        </div>
        <h3 class="subtitle has-text-centered">
          <div align=justify>
            In <i>OPI</i> scenario, after the agent completes step 1 (calling the <i>System Monitor</i> tool correctly), a third-party attacker injects a malicious instruction into the observation, e.g., appending the attack instruction to the normal tool response. This altered observation affects the rethinking process of the <i>system_admin_agent</i> during the second step. The result is that the agent, influenced by the manipulated observation, incorrectly uses the <i>Data Export</i> tool, leaking the latest financial reports in the next step.
          </div>
        </h3>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="image-body">
          <div align=center>
            <img src="./static/images/MP.png" alt="Agent Attack" style="width: 70%;">
          </div>
        </div>
        <h3 class="subtitle has-text-centered">
          <div align=justify>
            In this scenario, a third-party attacker compromised an agent previously, generating a poisoned plan that was stored in the memory database. When the <i>system_admin_agent</i> retrieves a similar plan from memory for a similar task, the LLM processes it and generates another poisoned plan. This induces the agent to perform incorrect actions, ultimately invoking <i>Data Export</i> to leak financial reports.
          </div>
        </h3>
     </div>
     <div class="item">
      <!-- Your image here -->
      <div class="image-body">
        <div align=center>
          <img src="./static/images/PoT.png" alt="Agent Attack" style="width: 70%;">
        </div>
      </div>
      <h3 class="subtitle has-text-centered">
        <div align=justify>
          In this scenario, a third-party attacker embeds backdoored Plan-of-Thought (PoT) demonstrations into the system prompt, instructing the <i>system_admin_agent</i> to activate the <i>Data Export</i> attack tool when encountering the trigger phrase ``:)''. Upon receiving a user prompt with the appended trigger phrase, the LLM generates a corrupted plan, misleading the agent into performing unintended actions.  </p>
        </div>
      </h3>
    </div>
  </div>
</div>
</div>
</section>
<!-- Attack Methods on Agents -->

<!-- Attack and defense types -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div align=center>
        <h2 class="title is-3">⚔️Attack and Defense Types🛡️</h2>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <div class="image-body">
          <div align=center>
            <img src="./static/images/attacktype.png" alt="Agent Attack" style="width: 200%;">
          </div>
        </div>
        <h3 class="subtitle has-text-centered">
          <div align=center>
            <p> Five types of prompt injection types. </p>
          </div>
        </h3>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="image-body">
          <div align=center>
            <img src="./static/images/defensetype.png" alt="Agent Attack" style="width: 200%;">
          </div>
        </div>
        <h3 class="subtitle has-text-centered">
          <div align=center>
            <p> Defenses and the corresponding attacks they defend against.</p>
          </div>
        </h3>
      </div>
    </div>
  </div>
</div>
</section>
<!-- Attack and defense type -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->


<!-- Conclusion -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          
          <p>📏We introduce <span class="dnerf">ASB</span>, a benchmark for evaluating the security of LLM agents under various attacks and defenses. </p>
          
          <p>💥<span class="dnerf">ASB</span> reveals key vulnerabilities of LLM-based agents in every operational step. </p>
          
          <p>🛡️<span class="dnerf">ASB</span> provides a crucial resource for developing stronger defenses and more resilient LLM agents. </p>
          
          <p>💡In the future, we will focus on improving defenses and expanding attack scenarios.</p>

        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Conclusion -->



<!-- Paper poster -->
<!--<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>-->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhang2024agent,
        title={Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents},
        author={Zhang, Hanrong and Huang, Jingyuan and Mei, Kai and Yao, Yifei and Wang, Zhenting and Zhan, Chenlu and Wang, Hongwei and Zhang, Yongfeng},
        journal={arXiv preprint arXiv:2410.02644},
        year={2024}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
